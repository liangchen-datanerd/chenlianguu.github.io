<!DOCTYPE html>
<html lang="en">





<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/apple-touch-icon.png">
  <link rel="icon" type="image/png" href="https://i.loli.net/2020/01/09/gqn1D9aJRP3iCcm.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
    <meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
  
  <meta name="description" content="enthusiast for Modern Data Stack">
  <meta name="author" content="Chen Liang">
  <meta name="keywords" content="">
  <title>Kubernetes部署Presto ~ Liang Chen - data enthusiast</title>

  <link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/5.10.2/css/all.min.css"  >
<link rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/css/bootstrap.min.css"  >
<link rel="stylesheet" href="https://cdn.staticfile.org/mdbootstrap/4.8.9/css/mdb.min.css"  >
<link rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/3.0.1/github-markdown.min.css"  >

<link rel="stylesheet" href="//at.alicdn.com/t/font_1067060_qzomjdt8bmp.css">



  <link rel="stylesheet" href="/lib/prettify/tomorrow-night-eighties.min.css"  >

<link rel="stylesheet" href="/css/main.css"  >


  <link rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css"  >


<meta name="generator" content="Hexo 4.2.1"></head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Liang Chen - data enthusiast</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/">Home</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/archives/">Archives</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/categories/">Categories</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/tags/">Tags</a>
          </li>
        
          
          
          
          
          <li class="nav-item">
            <a class="nav-link" href="/about/">About</a>
          </li>
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="view intro-2" id="background"
         style="background: url('https://i.loli.net/2020/01/09/iBerVkKW4fNmMLY.jpg')no-repeat center center;
           background-size: cover;
           background-attachment: fixed;">
      <div class="full-bg-img">
        <div class="mask rgba-black-light flex-center">
          <div class="container text-center white-text fadeInUp">
            <span class="h2" id="subtitle">
              
            </span>

            
              <br>
              
                <p class="mt-3">
                  <i class="fas fa-calendar-alt" aria-hidden="true"></i>&nbsp;
                  2020-03-28 5:47 
                </p>
              

              <p>
                
                  
                  &nbsp;<i class="far fa-chart-bar"></i>
                  <span class="post-count">
                    4.9k 字
                  </span>&nbsp;
                

                
                  
                  &nbsp;<i class="far fa-clock"></i>
                  <span class="post-count">
                      25 分钟
                  </span>&nbsp;
                

                
                  <!-- 不蒜子统计文章PV -->
                  
                  &nbsp;<i class="far fa-eye" aria-hidden="true"></i>&nbsp;
                  <span id="busuanzi_container_page_pv">
                    <span id="busuanzi_value_page_pv"></span> 次
                  </span>&nbsp;
                
              </p>
            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="py-5 z-depth-3" id="board">
        <div class="post-content mx-auto" id="post">
          <div class="markdown-body">
            <h2 id="一、介绍"><a href="#一、介绍" class="headerlink" title="一、介绍"></a>一、介绍</h2><blockquote>
<p>Presto</p>
</blockquote>
<p>Presto是一个分布式SQL查询引擎，用于查询分布在一个或多个不同数据源中的大数据集。完整安装包括一个Coordinator和多个Worker。 由客户端提交查询，从Presto命令行CLI提交到Coordinator。 Coordinator进行解析，分析并执行查询计划，然后分发处理队列到Worker。</p>
<p>Presto是完全基于内存的分布式大数据查询引擎，所有查询和计算都在内存中执行。</p>
<p>Presto的输入是SQL语句；输出是具体的SQL执行结果。</p>
<p>Presto可以对接不同的数据源，例如MySQL、Hive等。</p>
<p>Presto可以对SQL的查询过程进行优化，包括SQL本身的执行计划优化，以及用分布式查询提高并发等。</p>
<p>Presto不是数据库，并不能处理在线事务。</p>
<blockquote>
<p>ceph </p>
</blockquote>
<p>Ceph是当前非常流行的开源分布式存储系统，具有高扩展性、高性能、高可靠性等优点，同时提供块存储服务(rbd)、对象存储服务(rgw)以及文件系统存储服务(cephfs)，Ceph在存储的时候充分利用存储节点的计算能力，在存储每一个数据时都会通过计算得出该数据的位置，尽量的分布均衡。</p>
<blockquote>
<p>rook</p>
</blockquote>
<p>Rook是一个开放源码的云本机存储协调器，提供平台、框架和对各种存储解决方案的支持，以便与云本机环境进行本机集成。</p>
<p>Rook将存储软件转变为自我管理、自我扩展和自我修复的存储服务。它通过自动化部署、引导、配置、供应、扩展、升级、迁移、灾难恢复、监视和资源管理来实现这一点。Rook使用底层云本地容器管理、调度和协调平台提供的设施来执行其职责。</p>
<p>Rook利用扩展点深入集成到云本机环境中，为调度、生命周期管理、资源管理、安全、监控和用户体验提供无缝体验。</p>
<blockquote>
<p>基于kubernetes部署presto</p>
</blockquote>
<p>将presto数据持久化到ceph集群中，保证presto的数据高可用</p>
<h2 id="二、软件版本"><a href="#二、软件版本" class="headerlink" title="二、软件版本"></a>二、软件版本</h2><ul>
<li>Kubernetes v1.15（<code>单节点环境亦可</code>）</li>
<li>Rook v1.0.2</li>
<li>CentOS 7 </li>
<li>presto 332（prestosql版本）</li>
<li>jdk-8</li>
</ul>
<h2 id="三、部署rook及ceph"><a href="#三、部署rook及ceph" class="headerlink" title="三、部署rook及ceph"></a>三、部署rook及ceph</h2><p>rook的部署可以使用kubernetes的包管理工具<a href="https://helm.sh/" target="_blank" rel="noopener">helm</a>安装，由于rook及kubernetes版本众多以及涉及到相关源等问题，本文没有采用helm安装方式部署rook</p>
<pre><code class="shell">$ git clone https://github.com/rook/rook.git 
$ cd rook 
$ git checkout v1.0.2
$ cd cluster/examples/kubernetes/ceph/</code></pre>
<p><code>cluster/examples/kubernetes/ceph/</code>目录包含部署rook相关文件</p>
<p>安装Rook Common Objects &amp; Operator</p>
<pre><code class="shell">kubectl create -f common.yaml
kubectl create -f operator.yaml</code></pre>
<p>检查<code>rook-ceph-operator,rook-ceph-agent</code>, rook-discover`安装成功</p>
<pre><code class="shell">$ kubectl get pods -n rook-ceph 
NAME                                   READY       STATUS        RESTARTS    AGE 
rook-ceph-agent-chj4l                  1/1         Running       0           84s 
rook-ceph-operator-548b56f995-v4mvp    1/1         Running       0           4m5s 
rook-discover-vkkvl                    1/1         Running       0    </code></pre>
<h3 id="3-1-部署Rook-Ceph-Cluster"><a href="#3-1-部署Rook-Ceph-Cluster" class="headerlink" title="3.1 部署Rook Ceph Cluster"></a>3.1 部署Rook Ceph Cluster</h3><pre><code class="shell">kubectl apply -f cluster.yml</code></pre>
<p>检查是否部署成功</p>
<pre><code class="shell">kubectl get pods -n rook-ceph
NAME                                  READY   STATUS      RESTARTS   AGE
rook-ceph-agent-chl7b                 1/1     Running     0          4h14m
rook-ceph-agent-tbx4l                 1/1     Running     2          4h14m
rook-ceph-mgr-a-bf88cfdc4-wvhjb       1/1     Running     0          3h52m
rook-ceph-mon-a-df88f8cbf-dklvj       1/1     Running     0          3h53m
rook-ceph-operator-548b56f995-q47jb   1/1     Running     5          4h14m
rook-ceph-osd-0-655957b867-p8tf7      1/1     Running     0          3h51m
rook-ceph-osd-1-7578dc7874-f9q64      1/1     Running     0          3h50m
rook-ceph-osd-prepare-node-2-nvr7d    0/2     Completed   0          3h45m
rook-ceph-osd-prepare-node-3-2mm2p    0/2     Completed   0          3h45m
rook-discover-44789                   1/1     Running     3          4h14m
rook-discover-c4r7d                   1/1     Running     0          4h14m</code></pre>
<h3 id="3-2-测试ceph-cluster"><a href="#3-2-测试ceph-cluster" class="headerlink" title="3.2 测试ceph cluster"></a>3.2 测试ceph cluster</h3><p>创建StorageClass以便ceph cluster动态创建PV、</p>
<pre><code class="shell">kubectl create -f storageclass-test.yaml

# 查找Rook Operator
$ kubectl get pod -n rook-ceph --selector=app=rook-ceph-operator 
NAME                                  READY   STATUS    RESTARTS   AGE
rook-ceph-operator-548b56f995-q47jb   1/1     Running   5          4h23m

# 检查ceph cluster健康状态
kubectl exec -n rook-ceph -it rook-ceph-operator-548b56f995-q47jb -- ceph status
  cluster:
    id:     bed40efd-b3e8-4b18-b9a0-e8723f51e747
    health: HEALTH_OK

  services:
    mon: 1 daemons, quorum a (age 4h)
    mgr: a(active, since 3h)
    osd: 2 osds: 2 up (since 3h), 2 in (since 3h)

  data:
    pools:   1 pools, 100 pgs
    objects: 0 objects, 0 B
    usage:   13 GiB used, 22 GiB / 35 GiB avail
    pgs:     100 active+clean

# 查看ceph磁盘信息
kubectl exec -n rook-ceph -it rook-ceph-operator-548b56f995-q47jb -- ceph df
RAW STORAGE:
    CLASS     SIZE       AVAIL      USED       RAW USED     %RAW USED
    hdd       35 GiB     22 GiB     13 GiB       13 GiB         37.40
    TOTAL     35 GiB     22 GiB     13 GiB       13 GiB         37.40

POOLS:
    POOL            ID     STORED     OBJECTS     USED     %USED     MAX AVAIL
    replicapool      1        0 B           0      0 B         0        19 GiB</code></pre>
<h3 id="3-3-配置ceph-dashborad"><a href="#3-3-配置ceph-dashborad" class="headerlink" title="3.3 配置ceph dashborad"></a>3.3 配置ceph dashborad</h3><p>在cluster.yaml文件中默认已经启用了ceph dashboard，查看dashboard的service：</p>
<pre><code class="shell">[root@node-1 presto-kubernetes]# kubectl get svc -n rook-ceph
NAME                                     TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)             AGE
rook-ceph-mgr                            ClusterIP   10.1.73.175    &lt;none&gt;        9283/TCP            6h29m
rook-ceph-mgr-dashboard                  ClusterIP   10.1.228.105   &lt;none&gt;        8443/TCP            6h29m
rook-ceph-mgr-dashboard-external-https   NodePort    10.1.38.28     &lt;none&gt;        8443:30102/TCP      21m
rook-ceph-mon-a                          ClusterIP   10.1.130.153   &lt;none&gt;        6789/TCP,3300/TCP   6h31m</code></pre>
<p>rook-ceph-mgr-dashboard监听的端口是8443，创建nodeport类型的service以便集群外部访问。</p>
<pre><code class="shell">kubectl apply -f rook/cluster/examples/kubernetes/ceph/dashboard-external-https.yaml</code></pre>
<p>查看一下nodeport暴露的端口，这里是30102端口：</p>
<pre><code>[root@node-1 presto-kubernetes]# kubectl get svc -n rook-ceph
NAME                                     TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)             AGE
rook-ceph-mgr                            ClusterIP   10.1.73.175    &lt;none&gt;        9283/TCP            6h29m
rook-ceph-mgr-dashboard                  ClusterIP   10.1.228.105   &lt;none&gt;        8443/TCP            6h29m
rook-ceph-mgr-dashboard-external-https   NodePort    10.1.38.28     &lt;none&gt;        8443:30102/TCP      21m
rook-ceph-mon-a                          ClusterIP   10.1.130.153   &lt;none&gt;        6789/TCP,3300/TCP   6h31m</code></pre><p>获取Dashboard的登陆账号和密码</p>
<pre><code class="shell">[root@node-1 ~]# MGR_POD=`kubectl get pod -n rook-ceph | grep mgr | awk &#39;{print $1}&#39;`
[root@node-1 ~]# kubectl -n rook-ceph logs $MGR_POD | grep password
debug 2020-02-25 23:54:04.280 7ffb08d89700  0 log_channel(audit) log [DBG] : from=&#39;client.4198 -&#39; entity=&#39;client.admin&#39; cmd=[{&quot;username&quot;: &quot;admin&quot;, &quot;prefix&quot;: &quot;dashboard set-login-credentials&quot;, &quot;password&quot;: &quot;Wo9nf64nDs&quot;, &quot;target&quot;: [&quot;mgr&quot;, &quot;&quot;], &quot;format&quot;: &quot;json&quot;}]: dispatch
debug 2020-02-25 23:58:11.177 7f8606e0e700  0 log_channel(audit) log [DBG] : from=&#39;client.4373 -&#39; entity=&#39;client.admin&#39; cmd=[{&quot;username&quot;: &quot;admin&quot;, &quot;prefix&quot;: &quot;dashboard set-login-credentials&quot;, &quot;password&quot;: &quot;Wo9nf64nDs&quot;, &quot;target&quot;: [&quot;mgr&quot;, &quot;&quot;], &quot;format&quot;: &quot;json&quot;}]: dispatch</code></pre>
<p>找到username和password字段，我这里是admin，Wo9nf64nDs<br>打开浏览器输入任意一个Node的IP+nodeport端口，这里使用master节点 ip访问：<a href="https://localhost:30102/#/dashboard" target="_blank" rel="noopener">https://localhost:30102/#/dashboard</a></p>
<h2 id="四、部署presto"><a href="#四、部署presto" class="headerlink" title="四、部署presto"></a>四、部署presto</h2><h3 id="4-1-部署步骤"><a href="#4-1-部署步骤" class="headerlink" title="4.1 部署步骤"></a>4.1 部署步骤</h3><ul>
<li><p>构建镜像presto-server端机presto-cli端的镜像，hdfs-site及core-site配置文件可以构建到镜像中，方便后续配置hive connector。通过脚本<code>build_image.sh</code>构建</p>
<blockquote>
<p><code>presto-serve端Dockerfile</code></p>
</blockquote>
<pre><code class="dockerfile">FROM centos:centos7.5.1804

RUN mkdir -p /etc/hadoop/conf

ADD jdk-11.0.6_linux-x64_bin.tar.gz /opt
ADD presto-server-332.tar.gz /opt
ADD core-site.xml /etc/hadoop/conf
ADD hdfs-site.xml /etc/hadoop/conf
ADD hudi-presto-bundle-0.5.2-incubating-sources.jar /opt/presto-server-332/plugin/hive-hadoop2
ADD hudi-presto-bundle-0.5.2-incubating.jar /opt/presto-server-332/plugin/hive-hadoop2
ADD original-hudi-presto-bundle-0.5.2-incubating-sources.jar /opt/presto-server-332/plugin/hive-hadoop2
ADD original-hudi-presto-bundle-0.5.2-incubating.jar /opt/presto-server-332/plugin/hive-hadoop2

ENV PRESTO_HOME /opt/presto-server-332
ENV JAVA_HOME /opt/jdk-11.0.6
ENV PATH $JAVA_HOME/bin:$PATH</code></pre>
<blockquote>
<p><code>presto-client端的Dockerfile</code></p>
</blockquote>
<pre><code class="dockerfile">FROM openjdk:8-slim

ADD presto-cli-332-executable.jar /opt

RUN  mv /opt/presto-cli-332-executable.jar /opt/presto-cli  &amp;&amp; chmod +x /opt/presto-cli</code></pre>
</li>
</ul>
<ul>
<li><p>配置server端相关配置 <code>presto-config-cm.yaml</code></p>
<p>server端的配置<strong>注意</strong>两个地方</p>
<ul>
<li>每个presto节点的node.id需要不一样</li>
<li>jvm参数需要加上<code>-DHADOOP_USER_NAME=hdfs</code>及<code>-Dpresto-temporarily-allow-java8=true</code>确保presto以HDFS用户访问hdfs文件及解决presto安装jdk8报错的问题</li>
</ul>
<pre><code class="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: presto-config-cm
  namespace: presto
  labels:
    app: presto-coordinator
data:
  bootstrap.sh: |-
    #!/bin/bash

    cd /root/bootstrap

    mkdir -p $PRESTO_HOME/etc/catalog

    cat ./node.properties &gt; $PRESTO_HOME/etc/node.properties
    cat ./jvm.config &gt; $PRESTO_HOME/etc/jvm.config
    cat ./config.properties &gt; $PRESTO_HOME/etc/config.properties
    cat ./log.properties &gt; $PRESTO_HOME/etc/log.properties

    echo &quot;&quot; &gt;&gt; $PRESTO_HOME/etc/node.properties
    echo &quot;node.id=$HOSTNAME&quot; &gt;&gt; $PRESTO_HOME/etc/node.properties

    sed -i &#39;s/${COORDINATOR_NODE}/&#39;$COORDINATOR_NODE&#39;/g&#39; $PRESTO_HOME/etc/config.properties

    if ${COORDINATOR_NODE}; 
    then
      echo coordinator
    else 
      sed -i &#39;7d&#39; $PRESTO_HOME/etc/config.properties
      echo worker
    fi

    for cfg in ../catalog/*; do
      cat $cfg &gt; $PRESTO_HOME/etc/catalog/${cfg##*/}
    done

    $PRESTO_HOME/bin/launcher run --verbose
  node.properties: |-
    node.environment=production
    node.data-dir=/var/presto/data
  jvm.config: |-
    -server
    -Xmx16G
    -XX:-UseBiasedLocking
    -XX:+UseG1GC
    -XX:G1HeapRegionSize=32M
    -XX:+ExplicitGCInvokesConcurrent
    -XX:+ExitOnOutOfMemoryError
    -XX:+UseGCOverheadLimit
    -XX:+HeapDumpOnOutOfMemoryError
    -XX:ReservedCodeCacheSize=512M
    -Djdk.attach.allowAttachSelf=true
    -Djdk.nio.maxCachedBufferSize=2000000
    -Dpresto-temporarily-allow-java8=true
    -DHADOOP_USER_NAME=hdfs
  config.properties: |-
    coordinator=${COORDINATOR_NODE}
    node-scheduler.include-coordinator=true
    http-server.http.port=8080
    query.max-memory=10GB
    query.max-memory-per-node=1GB
    query.max-total-memory-per-node=2GB
    discovery-server.enabled=true
    discovery.uri=http://presto:8080
  log.properties: |-
    io.prestosql=DEBUG</code></pre>
</li>
<li><p>catalog相关配置<code>presto-catalog-config-cm.yaml</code></p>
<pre><code class="yaml">apiVersion: v1
kind: ConfigMap
metadata:
  name: presto-catalog-config-cm
  namespace: presto
  labels:
    app: presto-coordinator
data:
  hive.properties: |-
    connector.name=hive-hadoop2
    hive.metastore.uri=thrift://ip:9083
    hive.config.resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml
  mysql.properties: |-
    connector.name=mysql
    connection-url=jdbc:mysql://ip:30306
    connection-user=root
    connection-password=Qloud@dev?123
</code></pre>
</li>
<li><p>presto-svc、worker、coordinator、presto-cli的部署<code>deployment.yaml</code></p>
<pre><code class="yaml">apiVersion: v1
kind: Service
metadata:
  name: presto
  namespace: presto
spec:
  ports:
  - port: 8080
  selector:
    app: presto-coordinator
  type: NodePort
---
apiVersion: apps/v1
kind: Deployment
metadata:
    name: presto-coordinator
    namespace: presto
spec:
    replicas: 1
    revisionHistoryLimit: 10
    selector:
    matchLabels:
        app: presto-coordinator
    template:
    metadata:
        labels:
        app: presto-coordinator
    spec:
        containers:
        - name: presto-coordinator
            image: reg.chebai.org/presto/presto-server:332
            command: [&quot;bash&quot;, &quot;-c&quot;, &quot;sh /root/bootstrap/bootstrap.sh&quot;]
            ports:
            - containerPort: 8080
            env:
            - name: COORDINATOR_NODE
                value: &quot;true&quot;
            volumeMounts:
            - name: presto-config-volume
                mountPath: /root/bootstrap
            - name: presto-catalog-config-volume
                mountPath: /root/catalog
            - name: presto-data-volume
                mountPath: /var/presto/data
        volumes:
        - name: presto-config-volume
            configMap:
            name: presto-config-cm
        - name: presto-catalog-config-volume
            configMap:
            name: presto-catalog-config-cm
        - name: presto-data-volume
            emptyDir: {}
---
apiVersion: apps/v1
kind: Deployment
metadata:
    name: presto-worker
    namespace: presto
spec:
    replicas: 2
    revisionHistoryLimit: 10
    selector:
    matchLabels:
        app: presto-worker
    template:
    metadata:
        labels:
        app: presto-worker
    spec:
        containers:
        - name: presto-worker
            image: reg.chebai.org/presto/presto-server:332
            command: [&quot;bash&quot;, &quot;-c&quot;, &quot;sh /root/bootstrap/bootstrap.sh&quot;]
            ports:
            - containerPort: 8080
            env:
            - name: COORDINATOR_NODE
                value: &quot;false&quot;
            volumeMounts:
            - name: presto-config-volume
                mountPath: /root/bootstrap
            - name: presto-catalog-config-volume
                mountPath: /root/catalog
            - name: presto-data-volume
                mountPath: /var/presto/data
        volumes:
        - name: presto-config-volume
            configMap:
            name: presto-config-cm
        - name: presto-catalog-config-volume
            configMap:
            name: presto-catalog-config-cm
        - name: presto-data-volume
            emptyDir: {}
---
apiVersion: v1
kind: Pod
metadata:
    name: presto-cli
    namespace: presto
spec:
    containers:
    - name: presto-cli
    image: reg.chebai.org/presto/presto-cli:332
    command: [&quot;tail&quot;, &quot;-f&quot;, &quot;/dev/null&quot;]
    imagePullPolicy: Always
    restartPolicy: Always</code></pre>
</li>
<li><p>启动presto</p>
<pre><code class="shell">kubectl create -f presto-config-cm.yaml
kubectl create -f presto-catalog-config-cm.yaml
kubectl create -f deployment.yaml </code></pre>
</li>
<li><p>使用presto，找出外部地址</p>
<pre><code class="shell">[root@node-1 ~]# kubectl get svc -n presto
NAME     TYPE       CLUSTER-IP    EXTERNAL-IP   PORT(S)          AGE
presto   NodePort   10.1.27.143   &lt;none&gt;        8080:32151/TCP   27h</code></pre>
</li>
<li><p>使用presto-cli客户端连接不同connector</p>
<pre><code class="shell">kubectl exec -it presto-cli -n presto /opt/presto-cli -- --server presto:8080 --catalog hive --schema default</code></pre>
</li>
</ul>
<h3 id="4-2-挂载ceph卷到presto"><a href="#4-2-挂载ceph卷到presto" class="headerlink" title="4.2 挂载ceph卷到presto"></a>4.2 挂载ceph卷到presto</h3><blockquote>
<p>由于github开源版本，没有提供数据卷挂载，因此需要相关yaml文件进行修改，配置rook提供RBD服务</p>
</blockquote>
<p>rook可以提供以下3类型的存储：<br> Block: Create block storage to be consumed by a pod<br> Object: Create an object store that is accessible inside or outside the Kubernetes cluster<br> Shared File System: Create a file system to be shared across multiple pods<br>在提供（Provisioning）块存储之前，需要先创建StorageClass和存储池。K8S需要这两类资源，才能和Rook交互，进而分配持久卷（PV）。<br>在kubernetes集群里，要提供rbd块设备服务，需要有如下步骤：</p>
<ol>
<li>创建rbd-provisioner pod</li>
<li>创建rbd对应的storageclass</li>
<li>创建pvc，使用rbd对应的storageclass</li>
<li>创建pod使用rbd pvc</li>
</ol>
<p>通过rook创建Ceph Cluster之后，rook自身提供了rbd-provisioner服务，所以我们不需要再部署其provisioner。</p>
<pre><code class="shell"># 配置storageclass
kubectl apply -f rook/cluster/examples/kubernetes/ceph/storageclass.yaml

# 检查storageclass
kubectl get storageclass
NAME              PROVISIONER          AGE
rook-ceph-block   ceph.rook.io/block   171m</code></pre>
<blockquote>
<p>修改preso-kubernetes文件夹中的worker相关配置</p>
</blockquote>
<pre><code class="shell">vim deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: presto-worker
spec:
  replicas: 2
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app: presto-worker
  template:
    metadata:
      labels:
        app: presto-worker
    spec:
      initContainers:
        - name: wait-coordinator
          image:  chenlianguu/presto-server:dm-0.208
          command: [&quot;bash&quot;, &quot;-c&quot;, &quot;until curl -sf http://presto-coordinator-service:8080/ui/; do echo &#39;waiting for coordinator started...&#39;; sleep 2; done;&quot;]
      containers:
        - name: presto-worker
          image: chenlianguu/presto-server:dm-0.208
          command: [&quot;bash&quot;, &quot;-c&quot;, &quot;sh /root/bootstrap/bootstrap.sh&quot;]
          ports:
            - name: http-coord
              containerPort: 8080
              protocol: TCP
          env:
            - name: COORDINATOR_NODE
              value: &quot;false&quot;
          volumeMounts:
            - name: presto-config-volume
              mountPath: /root/bootstrap
            - name: presto-catalog-config-volume
              mountPath: /root/catalog
            - name: presto-data-volume
              mountPath: /var/presto/data
          readinessProbe:
            initialDelaySeconds: 10
            periodSeconds: 5
            exec:
              command: [&quot;bash&quot;, &quot;-c&quot;, &quot;curl -s http://presto-coordinator-service:8080/v1/node | tr &#39;,&#39; &#39;\n&#39; | grep -s $(hostname -i)&quot;]
      volumes:
        - name: presto-config-volume
          configMap:
            name: presto-config-cm
        - name: presto-catalog-config-volume
          configMap:
            name: presto-catalog-config-cm
        - name: presto-data-volume
          persistentVolumeClaim:
            claimName: presto-data-claim</code></pre>
<p>重新apply yaml文件</p>
<pre><code class="shell">kubectl aplly -f worker-deployment.yaml</code></pre>
<p>检查是否配置成功</p>
<pre><code class="shell">[root@node-1 ~]# kubectl get pv
NAME                                       CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS   CLAIM                       STORAGECLASS      REASON   AGE
pvc-1ff7bb97-238e-4ebd-bfc3-fb9db1ae5656   10Gi       RWO            Delete           Bound    default/presto-data-claim   rook-ceph-block            100m
[root@node-1 ~]# kubectl get pvc
NAME                STATUS   VOLUME                                     CAPACITY   ACCESS MODES   STORAGECLASS      AGE
presto-data-claim   Bound    pvc-1ff7bb97-238e-4ebd-bfc3-fb9db1ae5656   10Gi       RWO            rook-ceph-block   100m</code></pre>
<p>注意：这里的pv会自动创建，当提交了包含 StorageClass 字段的 PVC 之后，Kubernetes 就会根据这个 StorageClass 创建出对应的 PV，这是用到的是Dynamic Provisioning机制来动态创建pv，PV 支持 Static 静态请求，和动态创建两种方式。</p>
<pre><code class="shell"># ceph集群端检查
[root@node-1 ~]# kubectl exec -n rook-ceph -it rook-ceph-operator-548b56f995-q47jb -- rbd info -p replicapool pvc-1ff7bb97-238e-4ebd-bfc3-fb9db1ae5656
rbd image &#39;pvc-1ff7bb97-238e-4ebd-bfc3-fb9db1ae5656&#39;:
        size 10 GiB in 2560 objects
        order 22 (4 MiB objects)
        snapshot_count: 0
        id: 1dd4352e100d
        block_name_prefix: rbd_data.1dd4352e100d
        format: 2
        features: layering
        op_features:
        flags:
        create_timestamp: Wed Feb 26 05:23:09 2020
        access_timestamp: Wed Feb 26 05:23:09 2020
        modify_timestamp: Wed Feb 26 05:23:09 2020</code></pre>
<p>登陆pod检查rbd设备</p>
<pre><code class="shell">[root@node-1 presto-kubernetes]# kubectl exec -it worker-7b66b5cb5-d2vzt bash
root@worker-7b66b5cb5-d2vzt:/usr/lib/presto-server-0.167-t.0.3/etc# df -h
Filesystem                                                                                        Size  Used Avail Use% Mounted on
/dev/mapper/docker-253:0-203738-8a1bc94ee31c6ca3e406a6c740b84cd8bd2c681c568dc8a4007f273208bbd9fd   10G  1.4G  8.7G  14% /
tmpfs                                                                                              64M     0   64M   0% /dev
tmpfs                                                                                             1.9G     0  1.9G   0% /sys/fs/cgroup
/dev/mapper/centos-root                                                                            18G  6.3G   12G  36% /etc/hosts
shm                                                                                                64M     0   64M   0% /dev/shm
/dev/rbd0                                                                                          10G   33M   10G   1% /var/presto/data
tmpfs                                                                                             1.9G   12K  1.9G   1% /run/secrets/kubernetes.io/serviceaccount
tmpfs                                                                                             1.9G     0  1.9G   0% /proc/acpi
tmpfs                                                                                             1.9G     0  1.9G   0% /proc/scsi
tmpfs                                                                                             1.9G     0  1.9G   0% /sys/firmware</code></pre>
<h3 id="4-3-presto多源异构查询"><a href="#4-3-presto多源异构查询" class="headerlink" title="4.3 presto多源异构查询"></a>4.3 presto多源异构查询</h3><blockquote>
<p>相关connector采用configmap方式进行灵活配置，不同connector的配置参考<a href="https://prestosql.io/docs/current/connector.html" target="_blank" rel="noopener">官网Doc</a></p>
</blockquote>
<pre><code class="yaml"># 创建presto-catalog-config-cm.yaml
cat &lt;&lt; EOF &gt; ～/presto-kubernetes/presto-catalog-config-cm.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: presto-catalog-config-cm
  labels:
    app: presto-coordinator
data:
  # hive相关配置
  hive.properties: |-
    connector.name=hive-hadoop2
    hive.metastore.uri=thrift://hive-metastore-ip:9083
  # mysql相关配置
  mysql.properties: |-
    connector.name=mysql
    connection-url=jdbc:mysql://example.net:3306
    connection-user=root
    connection-password=secret
  cassandra.properties: |-
    connector.name=cassandra
    cassandra.contact-points=host1,host2
EOF</code></pre>
<p>配置好之后需要生效，重新apply <code>presto-catalog-config-cm.yaml</code> 并<strong>删除coordinator及word相关的pod</strong>，删除之后会重新生成新的pod，新的pod会载入新的connector配置</p>
<pre><code class="shell">kubectl apply -f presto-catalog-config-cm.yaml
kubectl apply -f coordinator-deployment.yaml
kubectl apply -f worker-deployment.yaml
kubectl get pods
NAME                           READY   STATUS    RESTARTS   AGE
coordinator-8549f46c58-q8ngm   1/1     Running   0          9m29s
worker-d64744f4d-8j2vg         1/1     Running   0          9m10s
kubectl delete pod coordinator-8549f46c58-q8ngm worker-d64744f4d-8j2vg</code></pre>
<h3 id="4-4-presto相关connect的测试"><a href="#4-4-presto相关connect的测试" class="headerlink" title="4.4 presto相关connect的测试"></a>4.4 presto相关connect的测试</h3><h4 id="4-4-1-presto查询hive中数据"><a href="#4-4-1-presto查询hive中数据" class="headerlink" title="4.4.1 presto查询hive中数据"></a>4.4.1 presto查询hive中数据</h4><p>首先准备hive环境，这里直接利用docker启动hive环境，简单方便高效快捷，参考github项目<a href="https://github.com/big-data-europe/docker-hive" target="_blank" rel="noopener">docker-hive</a></p>
<pre><code class="shell">git clone https://github.com/big-data-europe/docker-hive.git
cd docker-hive 
# 启动docker-hive
docker-compose up -d
# 查看启动状态
                 Name                                Command                  State                          Ports
--------------------------------------------------------------------------------------------------------------------------------------
docker-hive_datanode_1                    /entrypoint.sh /run.sh           Up (healthy)   0.0.0.0:50075-&gt;50075/tcp
docker-hive_hive-metastore-postgresql_1   /docker-entrypoint.sh postgres   Up             5432/tcp
`docker-hive_hive-metastore_1              entrypoint.sh /opt/hive/bi ...   Up             10000/tcp, 10002/tcp, 0.0.0.0:9083-&gt;9083/tcp`
docker-hive_hive-server_1                 entrypoint.sh /bin/sh -c s ...   Up             0.0.0.0:10000-&gt;10000/tcp, 10002/tcp
docker-hive_namenode_1                    /entrypoint.sh /run.sh           Up (healthy)   0.0.0.0:50070-&gt;50070/tcp
docker-hive_presto-coordinator_1          ./bin/launcher run               Up             0.0.0.0:8080-&gt;8080/tcp

# 往hive里边加载数据
docker-compose exec hive-server bash
# /opt/hive/bin/beeline -u jdbc:hive2://localhost:10000
  &gt; CREATE TABLE pokes (foo INT, bar STRING);
  &gt; LOAD DATA LOCAL INPATH &#39;/opt/hive/examples/files/kv1.txt&#39; OVERWRITE INTO TABLE pokes;</code></pre>
<p>hive-metastore的连接端口为9083，确认该端口处于监听状态 <code>presto连接hive进行测试</code></p>
<pre><code class="shell">kubectl exec -it presto-cli -n presto /opt/presto-cli -- --server presto:8080 --catalog hive --schema default
presto:default&gt; show schemas;
       Schema
--------------------
 default
 information_schema
(2 rows)

Query 20200409_121447_00002_3jete, FINISHED, 2 nodes
Splits: 18 total, 18 done (100.00%)
0:00 [2 rows, 35B] [16 rows/s, 290B/s]

presto:default&gt; show tables;
 Table
-------
 `pokes`
(1 row)

Query 20200409_121459_00003_3jete, FINISHED, 2 nodes
Splits: 18 total, 18 done (100.00%)
0:00 [1 rows, 22B] [9 rows/s, 201B/s]

presto:default&gt; select * from pokes;

Query 20200409_121548_00004_3jete, FAILED, 1 node
Splits: 16 total, 0 done (0.00%)
0:01 [0 rows, 0B] [0 rows/s, 0B/s]

Query 20200409_121548_00004_3jete failed: java.net.UnknownHostException: namenode</code></pre>
<p>可以找到hive中表，但是查询不成功，查询不成功是因为使用<code>docker-compose</code>方式搭建的hive环境，其中namenode节点和kubernetes中的presto不在一套网络环境中，无法解析namenode地址，有条件可以用hive集群测试，本次测试环境都基于单机。</p>
<h4 id="4-4-2-presto查询mysql中数据"><a href="#4-4-2-presto查询mysql中数据" class="headerlink" title="4.4.2 presto查询mysql中数据"></a>4.4.2 presto查询mysql中数据</h4><p>首先准备mysql环境，这里直接利用docker启动mysql环境</p>
<pre><code class="shell">docker run --name mysql -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.6.36
docker exec -it mysql /bin/bash
# 造数据
mysql -uroot -p123456
mysql&gt; create database test;
mysql&gt; use test;
Database changed
mysql&gt; create table user(id int not null, username varchar(32) not null, password varchar(32) not null);
mysql&gt; insert into user values(1,&#39;user1&#39;,&#39;password1&#39;);
mysql&gt; insert into user values(2,&#39;user2&#39;,&#39;password2&#39;);
mysql&gt; insert into user values(3,&#39;user3&#39;,&#39;password3&#39;);
mysql&gt; select * from user;
+----+----------+-----------+
| id | username | password  |
+----+----------+-----------+
|  1 | user1    | password1 |
|  2 | user2    | password2 |
|  3 | user3    | password3 |
+----+----------+-----------+
3 rows in set (0.00 sec)</code></pre>
<p>mysql的连接端口为3306，确认该端口处于监听状态 <code>presto连接mysql进行测试</code></p>
<pre><code class="shell">kubectl exec -it presto-cli -n presto /opt/presto-cli -- --server presto:8080 --catalog mysql --schema test
presto:test&gt; show tables;
 Table
-------
 user
(1 row)

Query 20200409_122956_00004_6mm78, FINISHED, 2 nodes
Splits: 18 total, 18 done (100.00%)
0:00 [1 rows, 18B] [10 rows/s, 187B/s]

presto:test&gt; select * from user;
 id | username | password
----+----------+-----------
  1 | user1    | password1
  2 | user2    | password2
  3 | user3    | password3
(3 rows)

Query 20200409_123010_00005_6mm78, FINISHED, 1 node
Splits: 17 total, 17 done (100.00%)
0:00 [3 rows, 0B] [10 rows/s, 0B/s]</code></pre>
<p><code>presto</code>可以查到mysql中的表及表数据</p>
<h4 id="4-4-3-presto查询cassandra中的数据"><a href="#4-4-3-presto查询cassandra中的数据" class="headerlink" title="4.4.3 presto查询cassandra中的数据"></a><strong>4.4.3 presto查询cassandra中的数据</strong></h4><p>首先准备mysql环境，这里直接利用docker启动cassandra环境</p>
<pre><code class="shell">docker run --name cassandra -p 9042:9042 -d cassandra:3.0</code></pre>
<p>连接数据库</p>
<img src="https://i.loli.net/2020/04/10/mQgKFSxtYNh8HGT.png" srcset="/img/loading.gif" style="zoom:50%;">

<p>准备数据</p>
<pre><code class="sql">CREATE KEYSPACE IF NOT EXISTS pimin_net
WITH REPLICATION = {&#39;class&#39;: &#39;SimpleStrategy&#39;,&#39;replication_factor&#39;:1};

USE pimin_net;

CREATE TABLE users (
id int,
user_name varchar,
PRIMARY KEY (id) );

INSERT INTO users (id,user_name) VALUES (1,&#39;china&#39;);
INSERT INTO users (id,user_name) VALUES (2,&#39;taiwan&#39;);

select * from users;
</code></pre>
<img src="https://i.loli.net/2020/04/13/FmflGnxRWAsLIgB.jpg" srcset="/img/loading.gif" style="zoom:50%;">

<p>查询数据</p>
<pre><code class="shell">kubectl exec -it presto-cli -n presto /opt/presto-cli -- --server presto:8080 --catalog cassandra --schema default
presto:pimin_net&gt; show tables;
 Table
-------
 users
(1 row)

Query 20200410_024828_00002_4ekb9, FINISHED, 2 nodes
Splits: 18 total, 18 done (100.00%)
0:00 [1 rows, 24B] [5 rows/s, 133B/s]

presto:pimin_net&gt; select * from users;
 id | user_name
----+-----------
  1 | china
  2 | taiwan
(2 rows)

Query 20200410_024834_00003_4ekb9, FINISHED, 1 node
Splits: 273 total, 273 done (100.00%)
0:02 [2 rows, 2B] [1 rows/s, 1B/s]

presto:pimin_net&gt;</code></pre>
<p>可以查询到cassandra中的数据</p>
<h3 id="4-5-弹性伸缩"><a href="#4-5-弹性伸缩" class="headerlink" title="4.5 弹性伸缩"></a>4.5 弹性伸缩</h3><pre><code class="shell">kubectl get deployment -n presto
NAME                  DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
presto-coordinator    1         1         1            1           21m
presto-worker         2         2         2            2           21m

kubectl scale deployment presto-worker --replicas=3 -n presto
deployment &quot;presto-worker&quot; scaled

kubectl get deployment
NAME                  DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
presto-coordinator    1         1         1            1           23m
presto-worker         3         3         3            3           23m</code></pre>
<h2 id="五、Trouble-Shooting"><a href="#五、Trouble-Shooting" class="headerlink" title="五、Trouble Shooting"></a>五、Trouble Shooting</h2><ul>
<li><p>Docker拉取镜像源time out或者拉取不上，增加docker镜像源，把163，阿里，Azure的docker加速器最好都加上</p>
<pre><code class="shell">vim /etc/docker/daemon.json

{
  &quot;registry-mirrors&quot;: [
        &quot;https://dockerhub.azk8s.cn&quot;,
        &quot;https://b3sst9pc.mirror.aliyuncs.com&quot;,
        &quot;https://hub-mirror.c.163.com&quot;
]
}

systemctl daemon-reload
systemctl restart docker</code></pre>
</li>
<li><p>presto查询hive数据出现io.prestosql.spi.PrestoException: Could not obtain block: BP-1548201263错误，<code>show tables</code> <code>desc table</code>正常显示，通过在presto的pod容器内部使用hdfs 命令ls可以查看目录，但是cat hdfs上面的文件报相同的错误，说明无法联通datanode默认的50010端口，使用telnet命令可查看远程服务器是否开放次端口，通过开放端口或者解决防火墙方式解决，能够telnet成功该端口即可解决该问题 参考<a href="https://groups.google.com/forum/#!topic/presto-users/4yWpzR-zrds" target="_blank" rel="noopener">presto hive connector error reading from HDFS</a></p>
</li>
</ul>
<h2 id="六、注意事项"><a href="#六、注意事项" class="headerlink" title="六、注意事项"></a>六、注意事项</h2><ul>
<li><strong>当更新configmap的时候，由于不支持热更新，需要销毁掉presto的work及coordinatoe相关pod，销毁之后新启动的pod会载入最新的相关配置</strong></li>
<li>prestosql-332版本要求jdk11，但hadoop对jdk11不兼容，需要使用jdk8，并在presto的jvm参数上面加上-Dpresto-temporarily-allow-java8=true</li>
</ul>
<h2 id="七、Ref"><a href="#七、Ref" class="headerlink" title="七、Ref"></a>七、Ref</h2><ul>
<li><a href="https://info.crunchydata.com/blog/crunchy-postgresql-operator-with-rook-ceph-storage" target="_blank" rel="noopener">Using the PostgreSQL Operator with Rook Ceph Storage</a></li>
<li><a href="https://github.com/dharmeshkakadia/presto-kubernetes" target="_blank" rel="noopener">presto-kubernetes</a></li>
<li><a href="https://github.com/big-data-europe/docker-hive" target="_blank" rel="noopener">docker-hive</a></li>
<li><a href="https://github.com/joshuarobinson/presto-on-k8s" target="_blank" rel="noopener">presto-on-k8s</a></li>
<li><a href="https://blog.csdn.net/networken/article/details/85772418" target="_blank" rel="noopener">kubernetes部署rook+ceph存储系统</a></li>
<li><a href="https://blog.csdn.net/ygqygq2/article/details/103014350" target="_blank" rel="noopener">kubernetes上部署rook-ceph存储系统</a></li>
<li><a href="https://blog.csdn.net/chenleiking/article/details/82493798" target="_blank" rel="noopener">在Kubernetes上部署Presto</a></li>
<li><a href="https://docker_practice.gitee.io/install/mirror.html" target="_blank" rel="noopener">Docker镜像加速器</a></li>
<li><a href="https://www.jianshu.com/p/ba730747cc8c" target="_blank" rel="noopener">Presto连接MySQL</a></li>
<li><a href="https://medium.com/@uprush/presto-with-kubernetes-and-s3-deployment-4e262849244a" target="_blank" rel="noopener">Presto with Kubernetes and S3 — Deployment</a></li>
<li>[Presto-Powered S3 Data Warehouse on Kubernetes](</li>
</ul>

            <hr>
          </div>
          <br>
          <div>
            <p>
            
              <span>
                <i class="iconfont icon-inbox"></i>
                
                  <a class="hover-with-bg" href="/categories/kubernetes">kubernetes</a>
                  &nbsp;
                
              </span>&nbsp;&nbsp;
            
            
              <span>
                <i class="iconfont icon-tag"></i>
                
                  <a class="hover-with-bg" href="/tags/%E9%83%A8%E7%BD%B2">部署</a>
                
                  <a class="hover-with-bg" href="/tags/kubernetes">kubernetes</a>
                
                  <a class="hover-with-bg" href="/tags/presto">presto</a>
                
                  <a class="hover-with-bg" href="/tags/rook">rook</a>
                
                  <a class="hover-with-bg" href="/tags/ceph">ceph</a>
                
              </span>
            
            </p>
            
              <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a href="https://zh.wikipedia.org/wiki/Wikipedia:CC_BY-SA_3.0%E5%8D%8F%E8%AE%AE%E6%96%87%E6%9C%AC" target="_blank" rel="nofollow noopener noopener">CC BY-SA 3.0协议</a> 。转载请注明出处！</p>
            
          </div>
        </div>
      </div>
    </div>
    <div class="d-none d-lg-block col-lg-2 toc-container">
      
  <div id="toc">
    <p class="h4"><i class="far fa-list-alt"></i>&nbsp;TOC</p>
    <div id="tocbot"></div>
  </div>

    </div>
  </div>
</div>

<!-- custom -->


<!-- Comments -->
<div class="col-lg-7 mx-auto nopadding-md">
  <div class="container comments mx-auto" id="comments">
    
      <br><br>
      
      
  <div id="vcomments" style="width: 90%; margin: 0 auto;"></div>
  <script defer src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script defer src="//unpkg.com/valine/dist/Valine.min.js"></script>

  <script>
    var notify = 'false' === true;
    var verify = 'false' === true;
    var oldLoad = window.onload;
    window.onload = function () {
      new Valine({
        el: '#vcomments',
        notify: notify,
        verify: verify,
        app_id: "lxvw2uH6C55B6fUR6xYK6Mip-gzGzoHsz",
        app_key: "rXGqk3FqqMJejwdD0DHPFxIX",
        placeholder: "说点什么",
        avatar: "retro",
        meta: ['nick', 'mail', 'link'],
        pageSize: "10",
      });
      oldLoad && oldLoad();
    };
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://valine.js.org" target="_blank" rel="nofollow noopener noopener">comments
      powered by Valine.</a></noscript>


    
  </div>
</div>

    
  </main>

  
    <a class="z-depth-1" id="scroll-top-button" href="#" role="button">
      <i class="fa fa-chevron-up scroll-top-arrow" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  <footer class="mt-5">
  <div class="text-center py-3">
    <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><b>Hexo</b></a>
    <i class="iconfont icon-love"></i>
    <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"> <b>Fluid</b></a>
    <br>

    
  
    <!-- 不蒜子统计PV -->
    
    &nbsp;<span id="busuanzi_container_site_pv">总访问量 
          <span id="busuanzi_value_site_pv"></span> 次</span>&nbsp;
  
  
    <!-- 不蒜子统计UV -->
    
    &nbsp;<span id="busuanzi_container_site_uv">总访客数 
            <span id="busuanzi_value_site_uv"></span> 人</span>&nbsp;
  
  <br>



    


    <!-- cnzz Analytics icon -->
    

  </div>
</footer>

<!-- SCRIPTS -->
<script src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script src="https://cdn.staticfile.org/popper.js/1.15.0/umd/popper.min.js" ></script>
<script src="https://cdn.staticfile.org/twitter-bootstrap/4.3.1/js/bootstrap.min.js" ></script>
<script src="https://cdn.staticfile.org/mdbootstrap/4.8.9/js/mdb.min.js" ></script>
<script src="/js/main.js" ></script>


  <script src="/js/lazyload.js" ></script>



  
    <script src="https://cdn.staticfile.org/tocbot/4.8.0/tocbot.min.js" ></script>
  
  <script src="/js/post.js" ></script>



  <script src="https://cdn.staticfile.org/smooth-scroll/16.1.0/smooth-scroll.min.js" ></script>



  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>


<!-- Plugins -->


  

  
    <!-- Google Analytics -->
    <script>
      (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r;
        i[r] = i[r] || function () {
          (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date();
        a = s.createElement(o),
          m = s.getElementsByTagName(o)[0];
        a.async = 1;
        a.src = g;
        m.parentNode.insertBefore(a, m)
      })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

      ga('create', 'UA-162099397-1', 'auto');
      ga('send', 'pageview');
    </script>
  

  

  

  <!-- cnzz Analytics -->
  



  <script src="https://cdn.staticfile.org/prettify/r298/prettify.min.js" ></script>
  <script>
    $(document).ready(function () {
      $('pre').addClass('prettyprint  linenums');
      prettyPrint();
    })
  </script>



  <script src="https://cdn.staticfile.org/typed.js/2.0.10/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "Kubernetes部署Presto&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script src="https://cdn.staticfile.org/anchor-js/4.2.0/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "false",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      getSearchFile(path);
      this.onclick = null
    }
  </script>



  <script src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <script>
    $("#post img:not(.no-zoom img, img[no-zoom])").each(
      function () {
        var element = document.createElement("a");
        $(element).attr("data-fancybox", "images");
        $(element).attr("href", $(this).attr("src"));
        $(this).wrap(element);
      }
    );
  </script>











</body>
</html>
